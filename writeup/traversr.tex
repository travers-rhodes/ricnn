\documentclass{article}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{float}
\usepackage{bm}
\graphicspath{{./}}
\usepackage[left=1cm,right=1cm,top=1cm,bottom=1cm]{geometry}
\begin{document}
\title{Rotation Invariance using Second-order Convolutional Neural Networks}

\section{Introduction}
We propose a non-trivial filter filter for a Convolutional Neural Network (CNN) that is invarient to rotations of the input image around the center of the filter. 
In particular we show how to construct such non-trivial rotationally-invarient filter by using a second-order convolutional neural network (SO-CNN) layer.
Our SO-CNN layer has the following two important properties that cannot both be attained by standard CNN filters.
One, it is rotationally invarient, and two, it is non-trivial. 
What we mean by non-trivial is that our single filter is able to distinguigsh a dumbbell from a donut, even if the donut looks exactly like the surface generated by a rotated dumbbell.
No standard filtering operation of a CNN can have both those properties since linearity of a CNN's filter opertation implies the second property cannot hold given the first.
Furthermore, the filter does not need to be trained on rotated views of its input image.
In \cite{chengzhouhan}, Cheng et al. build a neural network that is essentially rotation invarient.
In \cite{jaderberg}, Jaderberg builds a neural network that is invarient to rotations (more generally, to affine transformations of the input).
However, both of those papers require that the network be trained on several transformed input representations in order for the network to learn to be rotationally invarient.
Relatedly, neither of those networks is guaranteed mathematically to be invarient to rotations of the input image (even for square images rotated a quarter turn, for example).
We construct a non-trivial rotationally invarient filter that can be constructed from a single training image and does not need to be trained on multiple rotated views on an object.
Our filter is exactly rotationally invarient for rotations by a quarter turn, and the only reason it is only approximately invarient for other rotations is because of the rectangular nature of image pixels.
For sufficiently high-resolution pixels (or for pixels arranged finely enough along grid lines in polar coordinates) our method is guaranteed to be rotationally invarient to arbitrary precision.
Na\"ively, one might expect that rotationally invarient filters satisfy our goal trivially.
However, since a single filter is linear in its inputs, any rotationally invarient filter will return the same value for an image and for any weighted average of various rotations of that image.
We find this problematic because we would like our rotationally invarient filter to be able to distinguish objects like a donut from a dumbbell, even though if you rotate a dumbbell you get an object that looks like a donut.
We show how second-order filters have the desired properties.
Yu and Salzmann \cite{yusalzmann} give an explanation of second-order convolutional neural networks (SO-CNNs). 
However, they do not discuss the finding we present here, that due to their non-linear nature, second-order filters can be used to guarantee rotational invariance while disambiguating object images from weighted combinations of rotations of that object's image.

\section{The Problem Definition}
We would like to create a single filter that can be easily applied to any part of an image to detect an object and that is able to differentiate that object from linear combinations of rotated versions of that object (eg: able to distinguish a dumbbell from a donut).

No standard first-order filter is able to accomplish that task because first-order filters are linear in their inputs, so if they are invarient to rotation then they are also necessarily equally triggered by an image of that object and by a weighted average of images of rotations of that object.

However, we show that a second-order filter constructed using a rotationally invarient filter has the desired properties. In particular, we define our second-order as follows.

We construct an (approximately) rotationally-symmetric filter as follows. 
We assume a square filter of side length $2h + 1$. 
The pixels are defined by $\mathbf x = (x,y),\text{ for } x,y\in [-h,h]$ we define the radius $r$ of a pixel as $r_{\mathbf{x}} = ||x||_2$. 
To start with, we define the sets of pixels $S_r$ indexed by $r \in \mathbb Z, 0\le r \le h$:
\[S_r = \{\mathbf{x} \mid r \le r_{\mathbf{x}} < r+1\}\]
Points with $r_{\mathbf{x}} > h + 1$ are not in any set.
And we can therefore construct an approximately rotationally-invariant filter by setting the filter value $f(\mathbf{x})$ to be equal to some parameterized $f_r$ depending on which $S_r$ contains $x$. And we set $f(\mathbf{x}) = 0$ if $r_x >= h + 1$.
This approximately-rotationally symmetric filter has $h+1$ parameters. It could be improved using only slightly more complicated math downstream by doing linear interpolation and setting
$f(\mathbf{x}) = (r_x - r)f_r + (r + 1 - r_x)f_{r+1}$ (where r \le r_x < r+1) and $f_{k} = 0$ if $k > h$.
However, we show that the simpler filter definition is sufficient for practical purposes.








\bibliography{traversr}{}
\bibliographystyle{plain}
\end{document}
